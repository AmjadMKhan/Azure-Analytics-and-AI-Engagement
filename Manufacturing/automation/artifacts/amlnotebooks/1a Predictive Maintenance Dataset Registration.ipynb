{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure Machine Learning datasets for Predictive Maintenance \n",
    "\n",
    "Azure Machine Learning datasets can be extremely useful for your local or remote experiments. In this notebook, we will do the following things.\n",
    "\n",
    "1. Configure workspace using credentials for Azure subscription\n",
    "2. Download the dataset from ADLS Gen2\n",
    "3. Upload the featured dataset into the default datastore in Azure\n",
    "4. Register the featured dataset into Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure workspace using credentials for Azure subscription\n",
    "\n",
    "As part of the setup you have already created a Workspace. To run AutoML, you also need to create an Experiment. An Experiment corresponds to a prediction problem you are trying to solve, while a Run corresponds to a specific approach to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace configuration succeeded. Skip the workspace creation steps below\n"
     ]
    }
   ],
   "source": [
    "# Install the required package\n",
    "!pip install azure-storage-blob==2.1.0\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Importing user defined config\n",
    "import config\n",
    "\n",
    "# Import the subscription details as below to access the resources\n",
    "subscription_id=config.subscription_id\n",
    "resource_group=config.resource_group\n",
    "workspace_name=config.workspace_name\n",
    "\n",
    "try:\n",
    "    workspace = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    workspace.write_config()\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except:\n",
    "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the  dataset from ADLS Gen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.storage.blob.models.Blob at 0x7fdddf5eaf28>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## setting up the credentials for ADLS Gen2\n",
    "import os\n",
    "from azure.storage.blob import BlockBlobService\n",
    "\n",
    "# setting up blob storage configs\n",
    "STORAGE_ACCOUNT_NAME = config.STORAGE_ACCOUNT_NAME\n",
    "STORAGE_ACCOUNT_ACCESS_KEY = config.STORAGE_ACCOUNT_ACCESS_KEY\n",
    "STORAGE_CONTAINER_NAME = \"azureml-mfg\"\n",
    "\n",
    "blob_service = BlockBlobService(STORAGE_ACCOUNT_NAME, STORAGE_ACCOUNT_ACCESS_KEY) \n",
    "\n",
    "output_file_path=os.path.join(os.getcwd(),\"data\", \"mfg_pdm.csv\")\n",
    "output_blob_file= \"mfg_pdm.csv\"\n",
    "\n",
    "# Create a project_folder if it doesn't exist\n",
    "if not os.path.isdir('data'):\n",
    " os.mkdir('data')\n",
    "\n",
    "# uploading the csv to  the ADLSGen2 storage container\n",
    "blob_service.get_blob_to_path(STORAGE_CONTAINER_NAME, output_blob_file,output_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the featured dataset into the default datastore in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/mfg_pdm.csv\n",
      "Uploaded ./data/mfg_pdm.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from azureml.core.dataset import Dataset\n",
    "from scipy import sparse\n",
    "import os \n",
    " \n",
    "# Create a project_folder if it doesn't exist\n",
    "if not os.path.isdir('data'):\n",
    " os.mkdir('data')\n",
    " \n",
    " \n",
    "ds = workspace.get_default_datastore()\n",
    "ds.upload(src_dir='./data', target_path='mfgdata', overwrite=True, show_progress=True)\n",
    " \n",
    "final_df = Dataset.Tabular.from_delimited_files(path=ds.path('mfgdata/mfg_pdm.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the featured dataset into Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_registered = Dataset.get_by_name(amlworkspace,\"train_data\",version='latest')\n",
    "#train_data_registered.unregister_all_versions()\n",
    "\n",
    "train_data_registered = final_df.register(workspace=workspace,\n",
    "                                 name='pdmmfg',\n",
    "                                 description='Synapse Mfg data',\n",
    "                                 tags= {'type': 'Mfg', 'date':'2020'},\n",
    "                                 create_new_version=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
