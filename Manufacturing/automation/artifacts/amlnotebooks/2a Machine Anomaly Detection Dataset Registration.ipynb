{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure Machine Learning datasets for Anomaly Detection\n",
    "\n",
    "Azure Machine Learning datasets can be extremely useful for your local or remote experiments. In this notebook, we will do the following things.\n",
    "\n",
    "1. Configure workspace using credentials for Azure subscription\n",
    "2. Download the dataset from ADLS Gen2\n",
    "3. Upload the featured dataset into the default datastore in Azure\n",
    "4. Register the featured dataset into Azure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure workspace using credentials for Azure subscription\n",
    "\n",
    "As part of the setup you have already created a Workspace. To run AutoML, you also need to create an Experiment. An Experiment corresponds to a prediction problem you are trying to solve, while a Run corresponds to a specific approach to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace configuration succeeded. Skip the workspace creation steps below\n"
     ]
    }
   ],
   "source": [
    "# Install the required package\n",
    "!pip install azure-storage-blob==2.1.0\n",
    "\n",
    "# Import the libraries\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Importing user defined config\n",
    "import config\n",
    "\n",
    "# Import the subscription details as below to access the resources\n",
    "subscription_id=config.subscription_id\n",
    "resource_group=config.resource_group\n",
    "workspace_name=config.workspace_name\n",
    "\n",
    "try:\n",
    "    workspace = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    workspace.write_config()\n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except:\n",
    "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the  dataset from ADLS Gen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.storage.blob.models.Blob at 0x7f9e1ddada20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## setting up the credentials for ADLS Gen2\n",
    "import os\n",
    "from azure.storage.blob import BlockBlobService\n",
    "\n",
    "# setting up blob storage configs\n",
    "STORAGE_ACCOUNT_NAME = config.STORAGE_ACCOUNT_NAME\n",
    "STORAGE_ACCOUNT_ACCESS_KEY = config.STORAGE_ACCOUNT_ACCESS_KEY\n",
    "STORAGE_CONTAINER_NAME = \"azureml-mfg\"\n",
    "\n",
    "blob_service = BlockBlobService(STORAGE_ACCOUNT_NAME, STORAGE_ACCOUNT_ACCESS_KEY) \n",
    "\n",
    "# Create a project_folder if it doesn't exist\n",
    "if not os.path.isdir('anomalydata'):\n",
    " os.mkdir('anomalydata')\n",
    "\n",
    "output_file_path=os.path.join(os.getcwd(),\"anomalydata\", \"mfg_anomaly_pdm.csv\")\n",
    "output_blob_file= \"mfg_anomaly_pdm.csv\"\n",
    "\n",
    "# uploading the csv to  the ADLSGen2 storage container\n",
    "blob_service.get_blob_to_path(STORAGE_CONTAINER_NAME, output_blob_file,output_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the featured dataset into the default datastore in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./anomalydata/mfg_anomaly_pdm.csv\n",
      "Uploaded ./anomalydata/mfg_anomaly_pdm.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    }
   ],
   "source": [
    "#Uploading dataset to the Datastore \n",
    "from sklearn import datasets\n",
    "from azureml.core.dataset import Dataset\n",
    "from scipy import sparse\n",
    "import os \n",
    "\n",
    "ds = workspace.get_default_datastore()\n",
    "ds.upload(src_dir='./anomalydata', target_path='mfganomalydata', overwrite=True, show_progress=True)\n",
    " \n",
    "final_df = Dataset.Tabular.from_delimited_files(path=ds.path('mfganomalydata/mfg_anomaly_pdm.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the featured dataset into Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Registering the dataset in Azure  ML\n",
    "train_data_registered = final_df.register(workspace=workspace,\n",
    "                                 name='pdmanomalymfg',\n",
    "                                 description='Synapse Mfg data',\n",
    "                                 tags= {'type': 'Mfg', 'date':'2020'},\n",
    "                                 create_new_version=False)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
