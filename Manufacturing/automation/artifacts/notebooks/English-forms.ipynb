{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Relevant Libraries\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {},
      "source": [
        "import json\n",
        "import time\n",
        "import requests\n",
        "import os\n",
        "from azure.storage.blob import BlockBlobService\n",
        "import pprint\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import shutil\n",
        "import pickle"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Local Folders\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Create local directories if they don't exist\n",
        "# *mfg_source* contains all the pdf files to be converted to json\n",
        "if (not os.path.isdir(os.getcwd()+\"/form-datasets\")):\n",
        "    os.makedirs(os.getcwd()+\"/form-datasets\")\n",
        "# *formrecogoutput* will contain all the converted json files\n",
        "if (not os.path.isdir(os.getcwd()+\"/formrecogoutput\")):\n",
        "    os.makedirs(os.getcwd()+\"/formrecogoutput\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Downloading the PDF form from a cotainer\n",
        "\n",
        "Downloads all PDF from a container\n",
        "Does not download PDF which are already downloaded"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "CPU times: user 61.3 ms, sys: 4.19 ms, total: 65.5 ms\nWall time: 260 ms"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%time\n",
        "# Downloading pdf files from a container named *form-dataset* to a local folder *form-dataset**\n",
        "# Set up configs for blob storage\n",
        "STORAGE_ACCOUNT_NAME = \"#STORAGE_ACCOUNT_NAME#\"\n",
        "STORAGE_ACCOUNT_ACCESS_KEY = \"#STORAGE_ACCOUNT_KEY#\"\n",
        "STORAGE_CONTAINER_NAME = \"form-datasets\"\n",
        "\n",
        "# Instantiating a blob service object\n",
        "blob_service = BlockBlobService(STORAGE_ACCOUNT_NAME, STORAGE_ACCOUNT_ACCESS_KEY) \n",
        "\n",
        "blobs = blob_service.list_blobs(STORAGE_CONTAINER_NAME)\n",
        "# Downloading pdf files from the container *form-dataset** and storing them locally to *form-dataset** folder\n",
        "for blob in blobs:\n",
        "    # Check if the blob.name is already present in the folder form-dataset*. If yes then continue\n",
        "    if not blob.name.rsplit('.',1)[-1] == 'pdf':\n",
        "        continue\n",
        "    try:\n",
        "        with open('merged_log','rb') as f:\n",
        "            merged_files = pickle.load(f)\n",
        "    except FileNotFoundError:\n",
        "        merged_files = set()\n",
        "    # If file is already processed then continue to next file\n",
        "    if (blob.name in merged_files): \n",
        "        continue\n",
        "    download_file_path = os.path.join(os.getcwd(), \"form-datasets\", blob.name)\n",
        "    blob_service.get_blob_to_path(STORAGE_CONTAINER_NAME, blob.name ,download_file_path)\n",
        "    merged_files.add(blob.name)\n",
        "    # Keep trace of all the processed files at the end of your script (to keep track later)\n",
        "    with open('merged_log', 'wb') as f:\n",
        "        pickle.dump(merged_files, f)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "7"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# Total number of forms to be converted to JSON\n",
        "files = [f for f in listdir(os.getcwd()+\"/form-datasets\") if isfile(join(os.getcwd()+\"/form-datasets\", f))]\n",
        "len(files)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Querying the custom form recognizer model (PDF -> JSON)\n",
        "?\n",
        "Converts PDF -> JSON by querying the trained custom model.\n",
        "Clean the JSON file\n",
        "If a file has already been converted to JSON then skip it.## Cell title\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "POST analyze succeeded:\n{'Content-Length': '0', 'Operation-Location': 'https://westus2.api.cognitive.microsoft.com/formrecognizer/v2.0/custom/models/35392b7f-3504-4baf-b7c6-ce60315ee798/analyzeresults/b4cfc2aa-6b1f-43a7-b504-86741aa6810b', 'x-envoy-upstream-service-time': '77', 'apim-request-id': 'ed129c64-6cff-422b-99a0-c375105a7695', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Thu, 17 Sep 2020 13:49:17 GMT'}\nAnalysis succeeded:\n202045061\nPOST analyze succeeded:\n{'Content-Length': '0', 'Operation-Location': 'https://westus2.api.cognitive.microsoft.com/formrecognizer/v2.0/custom/models/35392b7f-3504-4baf-b7c6-ce60315ee798/analyzeresults/91b7c8fe-2b49-4faf-bd02-6bad7e3689c7', 'x-envoy-upstream-service-time': '97', 'apim-request-id': '6a324cf5-8f9e-4238-a87c-539d0fad7860', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Thu, 17 Sep 2020 13:49:33 GMT'}\nAnalysis succeeded:\n202045016\nPOST analyze succeeded:\n{'Content-Length': '0', 'Operation-Location': 'https://westus2.api.cognitive.microsoft.com/formrecognizer/v2.0/custom/models/35392b7f-3504-4baf-b7c6-ce60315ee798/analyzeresults/12c5d988-8cf6-4b51-9cce-77685255e354', 'x-envoy-upstream-service-time': '88', 'apim-request-id': 'a57f0545-294b-4d9a-8b50-26ff25f8c76a', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Thu, 17 Sep 2020 13:49:48 GMT'}\nAnalysis succeeded:\n202045001\nPOST analyze succeeded:\n{'Content-Length': '0', 'Operation-Location': 'https://westus2.api.cognitive.microsoft.com/formrecognizer/v2.0/custom/models/35392b7f-3504-4baf-b7c6-ce60315ee798/analyzeresults/d596df4f-c7ff-42e6-9fd6-820d0508ad98', 'x-envoy-upstream-service-time': '107', 'apim-request-id': '3f678604-b1bf-474c-8abe-0fb6cc07a045', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Thu, 17 Sep 2020 13:50:03 GMT'}\nAnalysis succeeded:\n202045060\nPOST analyze succeeded:\n{'Content-Length': '0', 'Operation-Location': 'https://westus2.api.cognitive.microsoft.com/formrecognizer/v2.0/custom/models/35392b7f-3504-4baf-b7c6-ce60315ee798/analyzeresults/2e091fb9-cf40-40a4-828e-6383e284360c', 'x-envoy-upstream-service-time': '86', 'apim-request-id': '1eddb6ef-613c-47d2-845c-73796972e2ab', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Thu, 17 Sep 2020 13:50:18 GMT'}\nAnalysis succeeded:\n202045005\nPOST analyze succeeded:\n{'Content-Length': '0', 'Operation-Location': 'https://westus2.api.cognitive.microsoft.com/formrecognizer/v2.0/custom/models/35392b7f-3504-4baf-b7c6-ce60315ee798/analyzeresults/75c213f2-0c45-42c9-8260-03db8998bee2', 'x-envoy-upstream-service-time': '148', 'apim-request-id': '4af472de-95f1-4518-9a6d-0aff19453db1', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Thu, 17 Sep 2020 13:50:35 GMT'}\nAnalysis succeeded:\n202045000\nPOST analyze succeeded:\n{'Content-Length': '0', 'Operation-Location': 'https://westus2.api.cognitive.microsoft.com/formrecognizer/v2.0/custom/models/35392b7f-3504-4baf-b7c6-ce60315ee798/analyzeresults/f0443609-8e23-456d-86a2-273395a0f0f8', 'x-envoy-upstream-service-time': '82', 'apim-request-id': 'af2b0f93-72e6-4fa6-abc7-b91dbea545ea', 'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'Date': 'Thu, 17 Sep 2020 13:50:50 GMT'}\nAnalysis succeeded:\n202045020\nCPU times: user 505 ms, sys: 43.8 ms, total: 549 ms\nWall time: 1min 47s"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%time\n",
        "# Endpoint parameters for querying the custom trained form-recognizer model to return the processed JSON\n",
        "# Processes PDF files one by one and return CLEAN JSON files\n",
        "endpoint = r\"https://#LOCATION#.api.cognitive.microsoft.com/\"\n",
        "# Change if api key is expired\n",
        "apim_key = \"#APIM_KEY#\"\n",
        "# This model is the one trained on 5 forms\n",
        "model_id = \"#MODEL_ID#\"\n",
        "post_url = endpoint + r\"/formrecognizer/v2.0/custom/models/%s/analyze\" % model_id\n",
        "params = {\"includeTextDetails\": True}\n",
        "headers = {'Content-Type': 'application/pdf', 'Ocp-Apim-Subscription-Key': apim_key}\n",
        "\n",
        "local_path = os.path.join(os.getcwd(), \"form-datasets\")\n",
        "output_path = os.path.join(os.getcwd(), \"formrecogoutput\")\n",
        "files = [f for f in listdir(local_path) if isfile(join(local_path, f))]\n",
        "\n",
        "for file in files:\n",
        "    if not file.rsplit('.',1)[-1] == 'pdf':\n",
        "        continue\n",
        "    try:\n",
        "        with open('json_log','rb') as l:\n",
        "            json_files = pickle.load(l)\n",
        "    except FileNotFoundError:\n",
        "        json_files = set()\n",
        "    if (file in json_files): \n",
        "        continue\n",
        "    else:\n",
        "        with open(join(local_path,file), \"rb\") as f:\n",
        "            data_bytes = f.read()\n",
        "        \n",
        "    try:\n",
        "        resp = requests.post(url = post_url, data = data_bytes, headers = headers, params = params)\n",
        "        if resp.status_code != 202:\n",
        "            print(\"POST analyze failed:\\n%s\" % json.dumps(resp.json()))\n",
        "            quit()\n",
        "        else:\n",
        "            print(\"POST analyze succeeded:\\n%s\" % resp.headers)\n",
        "            get_url = resp.headers[\"operation-location\"]\n",
        "    except Exception as e:\n",
        "        print(\"POST analyze failed:\\n%s\" % str(e))\n",
        "        quit()\n",
        "     \n",
        "    n_tries = 15\n",
        "    n_try = 0\n",
        "    wait_sec = 5\n",
        "    max_wait_sec = 60\n",
        "    while n_try < n_tries:\n",
        "        try:\n",
        "            resp = requests.get(url = get_url, headers = {\"Ocp-Apim-Subscription-Key\": apim_key})\n",
        "            resp_json = resp.json()\n",
        "            if resp.status_code != 200:\n",
        "                print(\"GET analyze results failed:\\n%s\" % json.dumps(resp_json))\n",
        "                quit()\n",
        "            status = resp_json[\"status\"]\n",
        "            if status == \"succeeded\":\n",
        "                print(\"Analysis succeeded:\\n%s\" % file[:-4])\n",
        "                allkeys = resp_json['analyzeResult']['documentResults'][0]['fields'].keys()\n",
        "                new_dict = {}\n",
        "                for i in allkeys:\n",
        "                    if resp_json['analyzeResult']['documentResults'][0]['fields'][i] != None:\n",
        "                        key = i.replace(\" \", \"_\")\n",
        "                        new_dict[key] = resp_json['analyzeResult']['documentResults'][0]['fields'][i]['valueString']\n",
        "                    else:\n",
        "                        key = i.replace(\" \", \"_\")\n",
        "                        new_dict[key] = None\n",
        "                # Appending form url to json\n",
        "                new_dict['form_url'] = 'https://#STORAGE_ACCOUNT_NAME#.blob.core.windows.net/form-datasets/' + file \n",
        "                with open(join(output_path,file[:-4]+\".json\"), 'w') as outfile:\n",
        "                    json.dump(new_dict, outfile)\n",
        "                # Change the encoding of file in case of spanish forms. It will detected random characters\n",
        "                with open(join(output_path,file[:-4]+\".json\"), 'w', encoding='utf-8') as outfile:\n",
        "                    json.dump(new_dict, outfile, ensure_ascii=False)\n",
        "                # Once JSON is saved log it otherwise don't log it.\n",
        "                json_files.add(file)\n",
        "                with open('json_log', 'wb') as f:\n",
        "                    pickle.dump(json_files, f)\n",
        "\n",
        "                break\n",
        "            if status == \"failed\":\n",
        "                print(\"Analysis failed:\\n%s\" % json.dumps(resp_json))\n",
        "                quit()\n",
        "            # Analysis still running. Wait and retry.\n",
        "            time.sleep(wait_sec)\n",
        "            n_try += 1\n",
        "            wait_sec = min(2*wait_sec, max_wait_sec)     \n",
        "        except Exception as e:\n",
        "            msg = \"GET analyze results failed:\\n%s\" % str(e)\n",
        "            print(msg)\n",
        "            quit()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Upload the JSON files to a cotainer## Cell title\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "7"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# Total number of converted JSON\n",
        "files = [f for f in listdir(output_path) if isfile(join(output_path, f))]\n",
        "len(files)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "CPU times: user 370 us, sys: 0 ns, total: 370 us\nWall time: 381 us"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%time\n",
        "# Connect to the container for uploading the JSON files\n",
        "# Set up configs for blob storage\n",
        "STORAGE_ACCOUNT_NAME = \"#STORAGE_ACCOUNT_NAME#\"\n",
        "STORAGE_ACCOUNT_ACCESS_KEY = \"#STORAGE_ACCOUNT_KEY#\"\n",
        "# Upload the JSON files in this container\n",
        "STORAGE_CONTAINER_NAME = \"formrecogoutput\"\n",
        "# Instantiating a blob service object\n",
        "blob_service = BlockBlobService(STORAGE_ACCOUNT_NAME, STORAGE_ACCOUNT_ACCESS_KEY)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1600347701065_0004/container_1600347701065_0004_01_000001/formrecogoutput\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1600347701065_0004/container_1600347701065_0004_01_000001/formrecogoutput/202045001.json\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1600347701065_0004/container_1600347701065_0004_01_000001/formrecogoutput/202045000.json\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1600347701065_0004/container_1600347701065_0004_01_000001/formrecogoutput/202045060.json\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1600347701065_0004/container_1600347701065_0004_01_000001/formrecogoutput/202045020.json\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1600347701065_0004/container_1600347701065_0004_01_000001/formrecogoutput/202045061.json\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1600347701065_0004/container_1600347701065_0004_01_000001/formrecogoutput/202045016.json\n/mnt/var/hadoop/tmp/nm-local-dir/usercache/trusted-service-user/appcache/application_1600347701065_0004/container_1600347701065_0004_01_000001/formrecogoutput/202045005.json\nCPU times: user 41.4 ms, sys: 4.18 ms, total: 45.6 ms\nWall time: 343 ms"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "%%time\n",
        "# Upload JSON files from local folder *formrecogoutput* to the container *formrecogoutput*\n",
        "local_path = os.path.join(os.getcwd(), \"formrecogoutput\")\n",
        "print(local_path)\n",
        "for files in os.listdir(local_path):\n",
        "    print(os.path.join(local_path,files))\n",
        "    blob_service.create_blob_from_path(STORAGE_CONTAINER_NAME, files, os.path.join(local_path,files))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [],
      "attachments": {}
    }
  ]
}